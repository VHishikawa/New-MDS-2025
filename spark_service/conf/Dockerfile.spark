# new_mds/spark_service/conf/Dockerfile.spark (Otimizado)

# Usar a imagem Bitnami Spark como base. É uma excelente escolha.
FROM bitnami/spark:3.5.6-debian-12-r1

# A imagem Bitnami já define SPARK_HOME, JAVA_HOME e o PATH.
# Confiaremos nas configurações otimizadas da imagem base.

# Troca para o usuário root para instalar dependências e ajustar permissões.
USER root

# ADICIONADO: Instala dependências de sistema que podem ser necessárias
# para compilar algumas bibliotecas Python (ex: build-essential).
# É uma boa prática para garantir que o 'pip install' não falhe.
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Copia os arquivos de configuração do Spark para dentro do container.
# Os arquivos devem estar na mesma pasta que este Dockerfile.
COPY log4j2.properties ${SPARK_HOME}/conf/log4j2.properties
COPY spark-defaults.conf ${SPARK_HOME}/conf/spark-defaults.conf

# Copia o novo arquivo de requisitos para um local temporário no contêiner.
COPY requirements.txt /tmp/requirements.txt

# Instala TODAS as bibliotecas Python a partir do arquivo requirements.txt.
# Isso centraliza a gestão de dependências e acelera o build com o cache do Docker.
RUN pip install --no-cache-dir -r /tmp/requirements.txt && \
    rm /tmp/requirements.txt

# Habilita a extensão de widgets para o JupyterLab (importante para o notebook interativo)
RUN jupyter labextension enable @jupyter-widgets/jupyterlab-manager

# Expõe as portas para comunicação do driver/executor Spark.
EXPOSE 4040 7007 7008

# A imagem da Bitnami gerencia a troca para um usuário não-root (1001)
# na execução, o que é uma boa prática de segurança. Não precisamos alterar.